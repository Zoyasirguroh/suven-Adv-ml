{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text standardization, Spelling correction and Tokenization\n",
    "--\n",
    "\n",
    "A> Standardizing Text\n",
    "--\n",
    "In this code example, we are going to discuss how to standardize the text. But before that, let’s understand what is text standardization and why we need to do it.\n",
    "\n",
    "Most of the text data is in the form of either customer reviews, blogs, or tweets, where there is a high chance of people using short words and abbreviations to represent the same meaning. This may help the downstream process to easily understand and resolve the semantics of the text.\n",
    "\n",
    "Problem\n",
    "--\n",
    "You want to standardize text.\n",
    "\n",
    "Solution\n",
    "--\n",
    "We can write our own custom dictionary to look for short words and\n",
    "abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom lookup dictionary\n",
    "# This dictionary will be for text standardization based on your data.\n",
    "\n",
    "lookup_dict = {'nlp':'natural language processing', 'ur':'your', \"wbu\" : \"what about you\"}\n",
    "\n",
    "import re\n",
    "\n",
    "# Create a custom function for text standardization\n",
    "\n",
    "def text_std(input_text):\n",
    " words = input_text.split()\n",
    " new_words = []\n",
    " for word in words:\n",
    "  word = re.sub(r'[^\\w\\s]','',word)\n",
    "  if word.lower() in lookup_dict:\n",
    "   word = lookup_dict[word.lower()]\n",
    "   new_words.append(word)\n",
    "   new_text = \" \".join(new_words)\n",
    "\n",
    " return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing your'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the text_std function\n",
    "\n",
    "text_std(\"I like nlp it's ur choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing your what about you'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_std(\"I like nlp it's ur choice, wbu\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here, nlp has standardised to 'natural language processing' and\n",
    "ur to 'your'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting Spelling\n",
    "--\n",
    "In this coding example, we are going to discuss how to do spelling correction. But before that, let’s understand why this spelling correction is important.\n",
    "Most of the text data is in the form of either customer reviews, blogs, or\n",
    "tweets, where there is a high chance of people using short words and making typo errors. This will help us in reducing multiple copies of words, which represents the same meaning. For example, “proccessing” and “processing” will be treated as different words even if they are used in the same sense.\n",
    "\n",
    "Note that abbreviations should be handled before this step, or else\n",
    "the corrector would fail at times. Say, for example, “ur” (actually means\n",
    "“your”) would be corrected to “or.”\n",
    "\n",
    "Problem\n",
    "--\n",
    "You want to do spelling correction.\n",
    "\n",
    "Solution\n",
    "--\n",
    "The simplest way to do this by using the TextBlob library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    tweet\n",
      "0                     Introduction to NLP\n",
      "1   It is likely to be useful, to people \n",
      "2  Machine learning is the new electrcity\n",
      "3                     R is good langauage\n",
      "4                        I like this book\n",
      "5             I want more books like this\n",
      "6                  angrezi medium realize\n"
     ]
    }
   ],
   "source": [
    "# Let’s create a list of strings and assign it to a variable.\n",
    "text=['Introduction to NLP','It is likely to be useful, to people ','Machine learning is the new electrcity', 'R is good langauage','I like this book','I want more books like this','angrezi medium realize']\n",
    "\n",
    "#convert list to dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'tweet':text})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        Introduction to NLP\n",
       "1      It is likely to be useful, to people \n",
       "2    Machine learning is the new electricity\n",
       "3                         R is good language\n",
       "4                           I like this book\n",
       "5                I want more books like this\n",
       "6                     angrezi medium realize\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install textblob library\n",
    "# !pip install textblob\n",
    "\n",
    "#import libraries and use 'correct' function of TextBlob\n",
    "\n",
    "## type your code here\n",
    "\n",
    "from textblob import TextBlob\n",
    "df['tweet'].apply(lambda x: str(TextBlob(x).correct()) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you clearly observe this, it corrected the spelling of electricity and\n",
    "language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autocorrect.spell is deprecated, use autocorrect.Speller instead\n",
      "message\n",
      "autocorrect.spell is deprecated, use autocorrect.Speller instead\n",
      "service\n"
     ]
    }
   ],
   "source": [
    "#You can also use autocorrect library as shown below\n",
    "\n",
    "#install autocorrect\n",
    "# !pip install autocorrect\n",
    "\n",
    "from autocorrect import spell\n",
    "from autocorrect import Speller\n",
    "print(spell(u'mussage'))\n",
    "print(spell(u'sirvice'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing Text\n",
    "--\n",
    "In this coding example, we would look at the ways to tokenize. \n",
    "\n",
    "Tokenization refers to splitting text into minimal meaningful units. There is a sentence tokenizer and word tokenizer. We will see a word tokenizer here, which is a mandatory step in text preprocessing for any kind of analysis. \n",
    "\n",
    "There are many libraries to perform tokenization like NLTK, SpaCy, and TextBlob. Here are a few ways to achieve it.\n",
    "\n",
    "Problem\n",
    "--\n",
    "You want to do tokenization.\n",
    "\n",
    "Solution\n",
    "--\n",
    "The simplest way to do this is by using the TextBlob library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet\n",
      "0                        This is introduction to NLP\n",
      "1              It is likely to be useful, to people \n",
      "2             Machine learning is the new electrcity\n",
      "3  There would be less hype around AI and more ac...\n",
      "4                           python is the best tool!\n",
      "5                                R is good langauage\n",
      "6                                   I like this book\n",
      "7                        I want more books like this\n"
     ]
    }
   ],
   "source": [
    "text=['This is introduction to NLP','It is likely to be useful, to people ','Machine learning is the new electrcity','There would be less hype around AI and more action going forward','python is the best tool!','R is good langauage', 'I like this book','I want more books like this']\n",
    "\n",
    "#convert list to dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'tweet':text})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['There', 'would', 'be', 'less', 'hype', 'around', 'AI', 'and', 'more', 'action', 'going', 'forward'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization Using textblob\n",
    "from textblob import TextBlob\n",
    "TextBlob(df['tweet'][3]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization using NLTK\n",
    "\n",
    "import nltk\n",
    "\n",
    "#create data\n",
    "mystring = df['tweet'][3]\n",
    "nltk.word_tokenize(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tokenization using split function from python\n",
    "mystring.split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
