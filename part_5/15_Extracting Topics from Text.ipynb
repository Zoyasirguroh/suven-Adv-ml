{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Topics from Text\n",
    "--\n",
    "In this section, we are going to discuss how to identify topics from the\n",
    "document. Say, for example, there is an online library with multiple departments based on the kind of book. As the new book comes in,\n",
    "you want to look at the unique keywords/topics and decide on which\n",
    "department this book might belong to and place it accordingly. In these\n",
    "kinds of situations, topic modeling would be handy.\n",
    "\n",
    "Basically, this is document tagging and clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem\n",
    "--\n",
    "You want to extract or identify topics from the document.\n",
    "\n",
    "Solution\n",
    "--\n",
    "The simplest way to do this by using the gensim library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am learning NLP, it is very interesting and exciting. it includes machine learning and deep learning',\n",
       " 'My father is a data scientist and he is nlp expert',\n",
       " 'My sister has good exposure into android development']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1: define some text documents\n",
    "\n",
    "doc1 = \"I am learning NLP, it is very interesting and exciting. it includes machine learning and deep learning\"\n",
    "doc2 = \"My father is a data scientist and he is nlp expert\"\n",
    "doc3 = \"My sister has good exposure into android development\"\n",
    "doc_complete = [doc1, doc2, doc3]\n",
    "doc_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['learning', 'nlp', 'interesting', 'exciting', 'includes', 'machine', 'learning', 'deep', 'learning'], ['father', 'data', 'scientist', 'nlp', 'expert'], ['sister', 'good', 'exposure', 'android', 'development']]\n"
     ]
    }
   ],
   "source": [
    "# step 2: Cleaning and preprocessing\n",
    "\n",
    "# Install and import libraries\n",
    "# !pip install gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Text preprocessing as discussed in chapter 2\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    " stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    " punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    " normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    " return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete]\n",
    "print(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 3), (5, 1), (6, 1)],\n",
       " [(6, 1), (7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: Preparing document term matrix\n",
    "\n",
    "# Importing gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our corpus, where every unique term \n",
    "# is assigned an index.\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting a list of documents (corpus) into Document-Term Matrix \n",
    "# using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.063*\"nlp\" + 0.063*\"father\" + 0.063*\"data\" + 0.063*\"scientist\" + 0.063*\"expert\" + 0.063*\"good\" + 0.063*\"exposure\" + 0.063*\"development\" + 0.063*\"android\" + 0.063*\"sister\"'), (1, '0.250*\"learning\" + 0.096*\"deep\" + 0.096*\"includes\" + 0.096*\"interesting\" + 0.096*\"machine\" + 0.096*\"exciting\" + 0.096*\"nlp\" + 0.019*\"scientist\" + 0.019*\"data\" + 0.019*\"father\"'), (2, '0.139*\"sister\" + 0.139*\"good\" + 0.139*\"exposure\" + 0.139*\"development\" + 0.139*\"android\" + 0.028*\"nlp\" + 0.028*\"father\" + 0.028*\"scientist\" + 0.028*\"data\" + 0.028*\"expert\"'), (3, '0.139*\"nlp\" + 0.139*\"father\" + 0.139*\"data\" + 0.139*\"scientist\" + 0.139*\"expert\" + 0.028*\"good\" + 0.028*\"exposure\" + 0.028*\"development\" + 0.028*\"android\" + 0.028*\"sister\"')]\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix for 3 topics.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=4, id2word=dictionary, passes=50)\n",
    "\n",
    "# Results\n",
    "print(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All the weights associated with the topics from the sentence seem\n",
    "almost similar. You can perform this on huge data to extract significant\n",
    "topics. The whole idea to implement this on sample data is to make you\n",
    "familiar with it, and you can use the same code snippet to perform on the\n",
    "huge data for significant results and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must watch twice for LDA\n",
    "https://www.youtube.com/watch?v=3mHy4OSyRf0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended Reading for all participants\n",
    "--\n",
    "https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d\n",
    "\n",
    "https://www.linkedin.com/pulse/lda-explanation-gaurhari-dass/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
